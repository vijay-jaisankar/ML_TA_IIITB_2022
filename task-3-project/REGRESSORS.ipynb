{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508621b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler,RobustScaler,LabelEncoder,OneHotEncoder\n",
    "import seaborn as sns\n",
    "\n",
    "# from helperFunctions import *\n",
    "# from customPreProc import * \n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ea956f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNullValueCounts(X):\n",
    "    print(X.isna().sum())\n",
    "\n",
    "def removeNaN(threshold,X,columns_to_delete,df):\n",
    "    null_percentage = X.isnull().sum()/len(X)*100\n",
    "    print('Removed: ')\n",
    "    # print(null_percentage[null_percentage>threshold])\n",
    "    # Below code gives list of columns having more than 60% null\n",
    "    col_to_drop = null_percentage[null_percentage>threshold].keys()\n",
    "    columns_to_delete.extend(col_to_drop)\n",
    "    X = X.drop(col_to_drop,axis=1)\n",
    "    print('old df : '+str(df.shape[1])+\" Columns\")\n",
    "    print('new df : '+str(X.shape[1])+\" Columns\")\n",
    "    return X,columns_to_delete\n",
    "\n",
    "def getUnique(X, flag):\n",
    "    for i in X.columns:\n",
    "        if flag == True:\n",
    "            print(i + \" : \" + str(len(X[i].unique())))\n",
    "        else:\n",
    "            print(i + \" : \" + str(X[i].unique())) \n",
    "\n",
    "# remove rows with more than 60% null values \n",
    "def removeNullRows (X,t):\n",
    "    before = X.shape[0]\n",
    "    X.dropna(thresh=int(t*X.shape[1]),inplace=True)\n",
    "    after = X.shape[0]\n",
    "    print(\"Rows with more than \"+str(int(t*X.shape[1]))+\" non null values will survive, deleted : \"+str(before-after))\n",
    "    return X\n",
    "\n",
    "def impute(X,feature,method=None,value=None,done = 0):\n",
    "    if done == 0:\n",
    "        print(\"percentage of null values : \"+str(X[feature].isna().sum()/X[feature].shape[0]))\n",
    "        print(\"mode : \"+str(X[feature].mode()))\n",
    "        print(\"mean : \"+str(X[feature].mean()))\n",
    "        print(\"Value counts : \"+str(X[feature].value_counts().head(7)))\n",
    "        print('\\n')\n",
    "\n",
    "        print(X[feature].describe())\n",
    "        i = input(\"want to change (y/n)\")\n",
    "        if i == 'y':\n",
    "            j = input(\"custom value or inbuilt method (c/i)\")\n",
    "            if j == 'c':\n",
    "                val = float(input('value : '))\n",
    "                X[feature].fillna(val,inplace=True)\n",
    "            else :\n",
    "                meth = str(input(\"Inbuilt method name : \"))\n",
    "                X[feature].fillna(method=meth,inplace=True)\n",
    "    else:\n",
    "        if value != None:\n",
    "            X[feature].fillna(value,inplace=True)\n",
    "        elif method != None:\n",
    "            X[feature].fillna(method=method,inplace=True)\n",
    "\n",
    "def fillNullRows(X):\n",
    "    try:\n",
    "        # X['DEF_60_CNT_SOCIAL_CIRCLE'].isna().sum()/X['DEF_60_CNT_SOCIAL_CIRCLE'].shape[0]\n",
    "\n",
    "        X['DEF_60_CNT_SOCIAL_CIRCLE'].fillna(0,inplace=True) # since most values are between 0 and 1\n",
    "        impute(X,\"OBS_60_CNT_SOCIAL_CIRCLE\", value = 0, done = 1) # ill fill it with 0 because onlu 0.3 % is null and both mean and mode are 0\n",
    "        impute(X,\"DEF_30_CNT_SOCIAL_CIRCLE\",value=0,done=1) # 0 because very less data is missing and mode is 0\n",
    "        impute(X,\"OBS_30_CNT_SOCIAL_CIRCLE\",value=1.4,done=1) # data is spread along first few values 0,1,2 \n",
    "        impute(X,\"TOTALAREA_MODE\",method=\"bfill\",done=1) # data is very evenly spread\n",
    "        impute(X, 'EXT_SOURCE_2', value = 0.566010, done = 1)\n",
    "        impute(X, 'AMT_ANNUITY', value = X['AMT_ANNUITY'].mean(), done = 1)\n",
    "        impute(X, 'BASEMENTAREA_MEDI', value = 0, done = 1)\n",
    "        impute(X, 'LANDAREA_MEDI', value = 0, done = 1)\n",
    "        # X['NAME_TYPE_SUITE'].fillna(value='Unaccompanied', inplace=True)\n",
    "        X['EMERGENCYSTATE_MODE'].fillna(value='No', inplace = True)\n",
    "        impute(X, 'EXT_SOURCE_1', value = 0.5025566902901272, done = 1)\n",
    "        impute(X, 'EXT_SOURCE_3', value = 0.510894, done = 1)\n",
    "        impute(X, 'APARTMENTS_MEDI', value = 0.0825, done = 1)\n",
    "        impute(X, 'YEARS_BEGINEXPLUATATION_MEDI', value = 0.9871, done = 1)\n",
    "        impute(X, 'ELEVATORS_MEDI', value = 0.000000, done = 1)\n",
    "        impute(X, 'ENTRANCES_MEDI', value = 0.1379, done = 1)\n",
    "        impute(X, 'FLOORSMAX_MEDI', value = 0.1667, done = 1)\n",
    "        impute(X, 'NONLIVINGAREA_MEDI', value = 0.0000, done = 1)\n",
    "        impute(X, 'AMT_REQ_CREDIT_BUREAU_HOUR', value = 0, done = 1)\n",
    "        impute(X, 'AMT_REQ_CREDIT_BUREAU_DAY', value = 0, done = 1)\n",
    "        impute(X, 'AMT_REQ_CREDIT_BUREAU_WEEK', value = 0, done = 1)\n",
    "        impute(X, 'AMT_REQ_CREDIT_BUREAU_MON', value = 0, done = 1)\n",
    "        impute(X, 'AMT_REQ_CREDIT_BUREAU_QRT', value = 0, done = 1)\n",
    "        impute(X, 'AMT_REQ_CREDIT_BUREAU_YEAR', value = 1.897504, done = 1)\n",
    "        impute(X, 'LIVINGAREA_MEDI', method = \"bfill\", done = 1)\n",
    "        # impute(X, 'OCCUPATION_TYPE', method = \"bfill\", done = 1)\n",
    "    except KeyError:\n",
    "        pass\n",
    "    cols_to_impute = ['APARTMENTS_AVG', 'BASEMENTAREA_AVG', 'YEARS_BEGINEXPLUATATION_AVG', 'ELEVATORS_AVG', 'ENTRANCES_AVG', 'FLOORSMAX_AVG', 'LANDAREA_AVG', 'LIVINGAREA_AVG', 'NONLIVINGAREA_AVG', 'APARTMENTS_MODE', 'BASEMENTAREA_MODE', 'YEARS_BEGINEXPLUATATION_MODE', 'ELEVATORS_MODE', 'ENTRANCES_MODE', 'FLOORSMAX_MODE', 'LANDAREA_MODE', 'LIVINGAREA_MODE', 'NONLIVINGAREA_MODE', 'AMT_GOODS_PRICE']\n",
    "    \n",
    "    for i in cols_to_impute:\n",
    "        try:\n",
    "            impute(X, i, value = X[i].mean(), done = 1)\n",
    "        except KeyError:\n",
    "            pass\n",
    "\n",
    "\n",
    "def dropRows(X):\n",
    "    try:\n",
    "        X.drop(X.index[X['TOTALAREA_MODE'].isnull()], inplace = True, axis = 0)\n",
    "        X.drop(X.index[X['LIVINGAREA_MEDI'].isnull()], inplace = True, axis = 0)\n",
    "        X.drop(axis = 0, index=X.index[X['DAYS_LAST_PHONE_CHANGE'].isnull()], inplace=True)\n",
    "        X.drop(axis = 0, index=X.index[X['CNT_FAM_MEMBERS'].isnull()], inplace=True)\n",
    "    except KeyError:\n",
    "        pass\n",
    "    return X\n",
    "#     return X\n",
    "\n",
    "def replaceValues(X):\n",
    "    try:\n",
    "        X[\"FLAG_OWN_REALTY\"] = X[\"FLAG_OWN_REALTY\"].replace(to_replace = \"Y\", value = 1)\n",
    "        X[\"FLAG_OWN_REALTY\"] = X[\"FLAG_OWN_REALTY\"].replace(to_replace = \"N\", value = 0)\n",
    "        X[\"FLAG_OWN_CAR\"] = X[\"FLAG_OWN_CAR\"].replace(to_replace = \"Y\", value = 1)\n",
    "        X[\"FLAG_OWN_CAR\"] = X[\"FLAG_OWN_CAR\"].replace(to_replace = \"N\", value = 0)\n",
    "    except KeyError:\n",
    "        pass\n",
    "    return X\n",
    "\n",
    "def encodeValues(X):\n",
    "    labelEncoder = LabelEncoder()\n",
    "    oneHotEncoder = OneHotEncoder()\n",
    "    try:\n",
    "        X['EMERGENCYSTATE_MODE'] = labelEncoder.fit_transform(X['EMERGENCYSTATE_MODE'])\n",
    "        X['NAME_CONTRACT_TYPE'] = labelEncoder.fit_transform(X['NAME_CONTRACT_TYPE'])\n",
    "        X = pd.get_dummies(X, columns = ['CODE_GENDER', 'NAME_TYPE_SUITE', 'NAME_INCOME_TYPE', 'NAME_EDUCATION_TYPE', 'NAME_FAMILY_STATUS', 'NAME_HOUSING_TYPE', 'ORGANIZATION_TYPE','OCCUPATION_TYPE', 'WEEKDAY_APPR_PROCESS_START','HOUR_APPR_PROCESS_START', 'WALLSMATERIAL_MODE','HOUSETYPE_MODE'])\n",
    "    except KeyError:\n",
    "        pass\n",
    "    return X\n",
    "\n",
    "'''Returns columns to drop , cols that are highly correlated'''\n",
    "def getCorr(X):\n",
    "    corr_matrix = X.corr().abs()\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "    to_drop = [column for column in upper.columns if any(upper[column] > 0.80)]\n",
    "    print(\"There are \"+str(len(to_drop))+\" corellated columns :\")\n",
    "    for i in to_drop:\n",
    "        print(i)\n",
    "#     columns_to_delete.extend(to_drop)\n",
    "    return to_drop\n",
    "\n",
    "\n",
    "def standardization(X,cols,method):\n",
    "    scaler = None\n",
    "\n",
    "    if method == \"minmax\":\n",
    "        scaler = MinMaxScaler()\n",
    "    elif method == \"stdsc\":\n",
    "        scaler = StandardScaler()\n",
    "    elif method == \"robust\":\n",
    "        scaler = RobustScaler()\n",
    "    else: \n",
    "        return X\n",
    "    return pd.DataFrame(scaler.fit_transform(X[cols]))\n",
    "\n",
    "def replaceNegativeColumns(X):\n",
    "    for i in X:\n",
    "        X[i] = X[i].abs()\n",
    "    return X\n",
    "\n",
    "def getCategoricalColumns(X):\n",
    "    categorical = []\n",
    "    numerical = []\n",
    "    for i in X:\n",
    "        if X[i].nunique() <= 2:\n",
    "            categorical.append(i)\n",
    "        else:\n",
    "            numerical.append(i)\n",
    "    return categorical, numerical\n",
    "def initdf():\n",
    "    df = pd.read_csv('./train_data.csv')\n",
    "    X = df.drop(['TARGET'],axis=1)\n",
    "    y = df['TARGET']\n",
    "    return df,X,y\n",
    "\n",
    "def getBoxPlot(X):\n",
    "    for i in range(0,len(X.columns)-5,6):\n",
    "        plt.figure(figsize=(18,9))\n",
    "        X[X.columns[i:i+6]].boxplot()\n",
    "        plt.title(\"Numerical variables in Modcloth dataset\", fontsize=20)\n",
    "        plt.show()\n",
    "def plotBox(X):\n",
    "    for i in range(0,len(X.columns)-5,6):\n",
    "        plt.figure(figsize=(18,9))\n",
    "        X[X.columns[i:i+6]].boxplot()\n",
    "        plt.title(\"Numerical variables in Modcloth dataset\", fontsize=20)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def remove_outlier_IQR(df):\n",
    "    Q1=df.quantile(0.25)\n",
    "    Q3=df.quantile(0.75)\n",
    "    IQR=Q3-Q1\n",
    "\n",
    "    lower_bracket = Q1-1.5*IQR\n",
    "    upper_bracket = Q3+1.5*IQR\n",
    "\n",
    "    lower = df[~(df<lower_bracket)].min()\n",
    "    upper = df[~(df>upper_bracket)].max()\n",
    "\n",
    "    arr = np.where(df > upper,np.nan,np.where(df < lower,np.nan, df))\n",
    "    pd.DataFrame(arr, index=df.index, columns=df.columns)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076fb06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_delete = []\n",
    "df = pd.read_csv('./train_data.csv')\n",
    "\n",
    "def initxy(df):\n",
    "    X = df.drop(['TARGET'],axis=1)\n",
    "    y = df['TARGET']\n",
    "    return X,y\n",
    "print(\"Percentage of 1s : \" + str((len(df['TARGET'][df['TARGET'] == 1])/len(df['TARGET'])) * 100) + \" %\")\n",
    "print(\"Percentage of 0s : \" + str((len(df['TARGET'][df['TARGET'] == 0])/len(df['TARGET'])) * 100) + \" %\")\n",
    "X = df\n",
    "cols_to_delete = ['SK_ID_CURR']\n",
    "columns_to_delete.extend(cols_to_delete)\n",
    "X.drop(cols_to_delete,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b9daf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_num = X.select_dtypes(exclude=['object'])\n",
    "pd.DataFrame(x_num).to_csv(\"numerical.csv\", index = False)\n",
    "categorical_cols = X.select_dtypes(include = ['object'])\n",
    "numerical_cols = X.select_dtypes(include = ['number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92715599",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Detecting outliers and filling it with NaN '''\n",
    "\n",
    "# from outliers import remove_outlier_IQR\n",
    "\n",
    "dfn = pd.read_csv('./numerical.csv')\n",
    "X_numeric = dfn.drop(['TARGET'],axis = 1 )\n",
    "y = dfn['TARGET']\n",
    "\n",
    "X_numeric = remove_outlier_IQR(X_numeric)\n",
    "\n",
    "print(len(X.columns))\n",
    "for col in X_numeric.columns:\n",
    "    X[col] = X_numeric[col]\n",
    "print(len(X.columns))\n",
    "\n",
    "# X has no outliers\n",
    "# Comment above code to contniue using data with outliers\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05a650c",
   "metadata": {},
   "source": [
    "### outlier detection end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e458b01",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "getNullValueCounts(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccf6805",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,columns_to_delete = removeNaN(65,X, columns_to_delete, df)\n",
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd1a5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = removeNullRows(X,0.65)\n",
    "print(\"new df size : \"+str(X.shape))\n",
    "\n",
    "X = replaceValues(X)\n",
    "\n",
    "''' Get columns with object type data'''\n",
    "dtype_object_list = X.select_dtypes(include=['object'])\n",
    "print('dtype_object_list shape',dtype_object_list.shape)\n",
    "\n",
    "fillNullRows(X)\n",
    "X = dropRows(X)\n",
    "X = encodeValues(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d87cbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "getNullValueCounts(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31151181",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_scalar = [\"DAYS_BIRTH\",\"DAYS_ID_PUBLISH\"] # for gaussian\n",
    "min_max = [\"CNT_CHILDREN\",\"AMT_INCOME_TOTAL\",\"AMT_CREDIT\",\"AMT_ANNUITY\",\"DAYS_REGISTRATION\",\"CNT_FAM_MEMBERS\",\"REGION_RATING_CLIENT\",\"REGION_RATING_CLIENT_W_CITY\",\"OBS_30_CNT_SOCIAL_CIRCLE\",\"DEF_30_CNT_SOCIAL_CIRCLE\",\"OBS_60_CNT_SOCIAL_CIRCLE\",\"DEF_60_CNT_SOCIAL_CIRCLE\",\"DAYS_LAST_PHONE_CHANGE\",\"AMT_REQ_CREDIT_BUREAU_QRT\",\"AMT_REQ_CREDIT_BUREAU_YEAR\"] #for non gaussian\n",
    "robust = [\"REGION_POPULATION_RELATIVE\",\"DAYS_EMPLOYED\"] #for outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb99cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "getNullValueCounts(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bc67cb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X.drop(X.index[X['AMT_CREDIT'].isnull()], axis = 0, inplace = True)\n",
    "\n",
    "y = X['TARGET']\n",
    "X = X.drop(['TARGET'],axis=1)\n",
    "\n",
    "fillNullRows(X)\n",
    "getNullValueCounts(X)\n",
    "X = replaceNegativeColumns(X)\n",
    "import re\n",
    "X = X.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6264f946",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = pd.read_csv('./test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f527e709",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_X = replaceValues(test_X)\n",
    "fillNullRows(test_X)\n",
    "test_X = encodeValues(test_X)\n",
    "impute(test_X, 'CNT_FAM_MEMBERS', method = 'bfill', done = 1)\n",
    "impute(test_X, 'LIVINGAREA_MEDI', value = 0.109127, done = 1)\n",
    "impute(test_X, 'TOTALAREA_MODE', value = 0.103063, done = 1)\n",
    "cols_to_impute = ['APARTMENTS_AVG', 'BASEMENTAREA_AVG', 'YEARS_BEGINEXPLUATATION_AVG', 'ELEVATORS_AVG', 'ENTRANCES_AVG', 'FLOORSMAX_AVG', 'LANDAREA_AVG', 'LIVINGAREA_AVG', 'NONLIVINGAREA_AVG', 'APARTMENTS_MODE', 'BASEMENTAREA_MODE', 'YEARS_BEGINEXPLUATATION_MODE', 'ELEVATORS_MODE', 'ENTRANCES_MODE', 'FLOORSMAX_MODE', 'LANDAREA_MODE', 'LIVINGAREA_MODE', 'NONLIVINGAREA_MODE']\n",
    "for i in cols_to_impute:\n",
    "    impute(test_X, i, value = test_X[i].mean(), done = 1)\n",
    "test_X_ID = test_X['SK_ID_CURR']\n",
    "columns_to_delete.append('NAME_FAMILY_STATUS_Unknown')\n",
    "test_X.drop(columns_to_delete, axis = 1, inplace=True)\n",
    "test_X = replaceNegativeColumns(test_X)\n",
    "getNullValueCounts(test_X)\n",
    "test_X = test_X.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3437d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "clf = lgb.LGBMClassifier()\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548d932b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "new_X_cols = []\n",
    "lgbFeatureSelection = pd.Series(clf.feature_importances_)\n",
    "lgbFeatureSelection.index = X.columns\n",
    "new_X_cols.extend(lgbFeatureSelection[lgbFeatureSelection > 20].index)\n",
    "lgbFeatureSelection.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff6571c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "no_of_ones = len(y_train[y_train == 1])\n",
    "no_of_zeros = len(y_train[y_train == 0])\n",
    "clf = lgb.LGBMClassifier(scale_pos_weight=(9.1985/2))\n",
    "clf.fit(X_train[new_X_cols],y_train)\n",
    "y_pred = clf.predict(X_test[new_X_cols])\n",
    "print(\"Training(Validation) Accuracy: \" + str(np.mean(y_pred == y_test) * 100))\n",
    "y_pred=clf.predict(test_X[new_X_cols])\n",
    "# len(X_test)\n",
    "soln_df = pd.DataFrame({\"SK_ID_CURR\" : test_X_ID, \"TARGET\" : y_pred})\n",
    "print(soln_df.value_counts([\"TARGET\"]))\n",
    "soln_df.to_csv(\"solution.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
